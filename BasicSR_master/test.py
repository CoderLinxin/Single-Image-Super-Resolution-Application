# import torch
#
# # torch.stack
# # 函数功能
# # 沿一个新维度对输入一系列张量进行连接，序列中所有张量应为相同形状，stack 函数返回的结果会新增一个维度。
# # 也即是把多个2维的张量凑成一个3维的张量；多个3维的凑成一个4维的张量…以此类推，也就是在增加新的维度上面进行堆叠
#
# # 参数列表
# # tensors：为一系列输入张量，类型为 tuple 和 List
# # dim：新增维度的（下标）位置，当 dim = -1 时默认最后一个维度；范围必须介于 [0,n], n 为输入张量的维数(len(shape))，默认是 dim=0,在第 0 维进行连接
# # 返回值：输出新增维度后的张量
#
# a = torch.tensor([
#     [
#         [1, 2, 3],
#         [4, 5, 6],
#         [7, 8, 9]
#     ],
#     [
#         [10, 20, 30],
#         [40, 50, 60],
#         [70, 80, 90]
#     ]
# ])
#
# b = torch.tensor([
#     [
#         [11, 22, 33],
#         [44, 55, 66],
#         [77, 88, 99]
#     ],
#     [
#         [110, 220, 330],
#         [440, 550, 660],
#         [770, 880, 990]
#     ]
# ])
#
# print(a.size())
# # torch.Size([2, 3, 3])
# print(b.size())
# # torch.Size([2, 3, 3])
#
# # 在第 0 维进行连接(增加的维度在第0维)，取整个 a 作为新 tensor 的一个分量，取整个 b 作为新 tensor 的一个分量
# # 其中 c[0] = a, c[1] = b
# c = torch.stack([a, b], dim=0)
# print(c)
# # tensor([[[[  1,   2,   3],
# #           [  4,   5,   6],
# #           [  7,   8,   9]],
# #          [[ 10,  20,  30],
# #           [ 40,  50,  60],
# #           [ 70,  80,  90]]],
# #
# #         [[[ 11,  22,  33],
# #           [ 44,  55,  66],
# #           [ 77,  88,  99]],
# #          [[110, 220, 330],
# #           [440, 550, 660],
# #           [770, 880, 990]]]])
# print(c.size())
# # torch.Size([2, 2, 3, 3])
#
# # 在第 1 维进行连接(增加的维度在第1维):
# # 取a的第0维数据[[1,2,3],[4,5,6],[7,8,9]],取b的第0维数据[[11,22,33],[44,55,66],[77,88,99]]作为新tensor的一个分量
# # 取a的第0维数据[[10,20,30],[40,50,60],[70,80,90]],取b的第0维数据[[110,220,330],[440,550,660],[770,880,990]]作为新tensor的另一个分量
# # 即 c[0][0] = a[0], c[0][0] = b[0]
# # 即 c[0][1] = a[1], c[0][1] = b[1]
# c = torch.stack([a, b], dim=1)
# print(c)
# # tensor([[[[  1,   2,   3],
# #           [  4,   5,   6],
# #           [  7,   8,   9]],
# #          [[ 11,  22,  33],
# #           [ 44,  55,  66],
# #           [ 77,  88,  99]]],
# #
# #         [[[ 10,  20,  30],
# #           [ 40,  50,  60],
# #           [ 70,  80,  90]],
# #          [[110, 220, 330],
# #           [440, 550, 660],
# #           [770, 880, 990]]]])
# print(c.size())
# # torch.Size([2, 2, 3, 3])
#
# # 在第2维进行连接(增加的维度在第2维):
# # 取a的第1维数据[1, 2, 3],取b的第1维数据[11, 22, 33]作为新tensor的一个分量
# # 取a的第1维数据[4, 5, 6],取b的第1维数据[44, 55, 66]作为新tensor的一个分量
# # 取a的第1维数据[7, 8, 9],取b的第1维数据[77, 88, 99]作为新tensor的一个分量
# # 取a的第1维数据[10, 20, 30],取b的第1维数据[110, 220, 330]作为新tensor的一个分量
# # 取a的第1维数据[40, 50, 60],取b的第1维数据[440, 550, 660]作为新tensor的一个分量
# # 取a的第1维数据[70, 80, 90],取b的第1维数据[770, 880, 990]作为新tensor的一个分量
# # 即 c[0][0][0] = a[0][0], c[0][0][1] = b[0][0]
# # 即 c[0][1][0] = a[0][1], c[0][1][1] = b[0][1]
# # 即 c[0][2][0] = a[0][2], c[0][2][1] = b[0][2]
#
# # 即 c[1][0][0] = a[1][0], c[1][0][1] = b[1][0]
# # 即 c[1][1][0] = a[1][1], c[1][1][1] = b[1][1]
# # 即 c[1][2][0] = a[1][2], c[1][2][1] = b[1][2]
# c = torch.stack([a, b], dim=2)
# print(c)
# # tensor([[[[  1,   2,   3],
# #           [ 11,  22,  33]],
# #          [[  4,   5,   6],
# #           [ 44,  55,  66]],
# #          [[  7,   8,   9],
# #           [ 77,  88,  99]]],
# #
# #         [[[ 10,  20,  30],
# #           [110, 220, 330]],
# #          [[ 40,  50,  60],
# #           [440, 550, 660]],
# #          [[ 70,  80,  90],
# #           [770, 880, 990]]]])
# print(c.size())
# # torch.Size([2, 3, 2, 3])
#
# # 在第3维进行连接(增加的维度在第3维):
# # 取a的第2维数据1,取b的第2维数据11作为新tensor的一个分量
# # 取a的第2维数据2,取b的第2维数据22作为新tensor的一个分量
# # ..
# # 取a的第2维数据99,取b的第2维数据990作为新tensor的一个分量
# # 即 c[0][0][0][0] = a[0][0][0], c[0][0][0][1] = b[0][0][0],
# # 即 c[0][0][1][0] = a[0][0][1], c[0][0][1][1] = b[0][0][1],
# # 即 c[0][0][2][0] = a[0][0][2], c[0][0][2][1] = b[0][0][2],
#
# # 即 c[0][1][0][0] = a[0][1][0], c[0][1][0][1] = b[0][1][0],
# # 即 c[0][1][1][0] = a[0][1][1], c[0][1][1][1] = b[0][1][1],
# # 即 c[0][1][2][0] = a[0][1][2], c[0][1][2][1] = b[0][1][2],
#
# # ...
#
# # 即 c[1][2][0][0] = a[1][2][0], c[1][2][0][1] = b[1][2][0],
# # 即 c[1][2][1][0] = a[1][2][1], c[1][2][1][1] = b[1][2][1],
# # 即 c[1][2][2][0] = a[1][2][2], c[1][2][2][1] = b[1][2][2],
#
# # 即 c[m,0,n] = a[m,n], c[m,1,n] = b[m,n]
# # 索引 0、1 位置代表沿 dim 拼接的索引位置
# c = torch.stack([a, b], dim=3)
# print(c)
# # tensor([[[[  1,  11],
# #           [  2,  22],
# #           [  3,  33]],
# #          [[  4,  44],
# #           [  5,  55],
# #           [  6,  66]],
# #          [[  7,  77],
# #           [  8,  88],
# #           [  9,  99]]],
# #
# #         [[[ 10, 110],
# #           [ 20, 220],
# #           [ 30, 330]],
# #          [[ 40, 440],
# #           [ 50, 550],
# #           [ 60, 660]],
# #          [[ 70, 770],
# #           [ 80, 880],
# #           [ 90, 990]]]])
# print(c.size())
# # torch.Size([2, 3, 3, 2])

# import torch
#
# a = torch.Tensor([
#     [1, 2, 3],
#     [4, 5, 6],
#     [7, 8, 9]
# ])
# print(a.size())
# # torch.Size([3, 3])
#
# b = torch.chunk(a, 3, dim=0)
# print(b)
# # (
# #  tensor([[1., 2., 3.]]),
# #  tensor([[4., 5., 6.]]),
# #  tensor([[7., 8., 9.]])
# # )
# print(b[0].size())
# # torch.Size([1, 3])
#
# c = torch.chunk(a, 3, dim=1)
# print(c)
# # (
# #     tensor([[1.],
# #             [4.],
# #             [7.]]),
# #     tensor([[2.],
# #             [5.],
# #             [8.]]),
# #     tensor([[3.],
# #             [6.],
# #             [9.]])
# # )
# print(c[0].size())
# # torch.Size([3, 1])

# import torch
#
# a1 = torch.tensor([1, 0, 2])
# print(a1.size())
# # torch.Size([3])
#
# b1 = a1.expand(2, -1)  # 第一个维度为升维，第二个维度保持原样
# print(b1)
# # tensor([[1, 0, 2],
# #         [1, 0, 2]])
# print(b1.size())
# # torch.Size([2, 3])
#
# a2 = torch.tensor([
#     [1],
#     [0],
#     [2]
# ])
# print(a2.size())
# # torch.Size([3, 1])
#
# b2 = a2.expand(-1, 2)  # 保持第一个维度，第二个维度只有一个元素，可扩展
# print(b2)
# # tensor([[1, 1],
# #         [0, 0],
# #         [2, 2]])
# print(b2.size())
# # torch.Size([3, 2])
#
# # 与 torch.repeat 的区别:
# # torch.expand 不会占用额外空间，只是在存在的张量上创建一个新的视图
# # torch.repeat 和 torch.expand 不同，它是拷贝了数据，会占用额外的空间

# import torch
#
# # torch.meshgrid
# # 生成网格，可以用于生成坐标。
# # 函数输入两个数据类型相同的一维张量，当两个输入张量数据类型不同或维度不是一维时会报错。
# # torch.meshgrid(*tensors, indexing=None)
# # indexing = ‘ij’ 行优先（默认）
# # indexing = ‘xy’ 列优先
# # 行优先
# #   输入的第一个Tensor确定行数，和每行的值，然后向右复制。也可以看做是确定了第一列。
# #   输入的第二个Tensor确定列数，以及每一列的值，然后向下复制。
# #   一般情况下，torch.meshgrid的输入参数中，有两个tensor，均应该是一维的tensor。
# #   如torch.meshgrid(a_tensor, b_tensor, indexing=’ij’)，
# #   表示首先把a_tensor当做第一列，然后根据b_tensor的元素数量，确定复制几列(对应返回的第一个元组元素)。
# #   接着把b_tensor当做第一行，然后根据a_tensor的元素数量，确定复制几行(对应返回的第二个元组元素)。
# #   总结起来就是“向右向下复制”
# # 列优先
# #   与“列优先”相反，第一个Tensor先确定列数和每列的取值，第二个Tensor先确定行数和每行的取值。
#
# # 以行优先为例,生成 hxw=2x3 的网格坐标:
# # 高为2,对应y的坐标len(0~1)=2,每一行y的坐标相同,对应到将arange(2)当成第一列然后向右复制3列,对应行优先下作为meshgrid的第一个参数
# # 宽为3,对应x的坐标len(0~2)=3,每一列x的坐标相同,对应到将arange(3)当成第一行然后向下复制2行,对应行优先下作为meshgrid的第二个参数
# h = torch.arange(2)
# w = torch.arange(3)
#
# y, x = torch.meshgrid([h, w], indexing='ij')
# print(x)
# # tensor([[0, 1, 2],
# #         [0, 1, 2]]) size = [2, 3]
# print(y)
# # tensor([[0, 0, 0],
# #         [1, 1, 1]]) size = [2, 3]
# print(torch.stack((x, y), 2))
# # 得到 2x3 的网格坐标
# # tensor([
# #   [[0, 0],[1, 0],[2, 0]],
# #   [[0, 1],[1, 1],[2, 1]]
# # ]) size = [2, 3, 2]

import torch

a = torch.Tensor([
    [1, 2, 3],
    [4, 5, 6]
])
b = torch.Tensor([1, 2, 3])
print(a.size())
# torch.Size([2, 3])
print(b.size())
# torch.Size([3])

print(a * b)
print((a+b).size())
# tensor([[ 1.,  4.,  9.],
#         [ 4., 10., 18.]])
# torch.Size([2, 3])